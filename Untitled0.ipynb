{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sQjJwIxg9atf",
        "outputId": "2e74e8b9-1ddf-4ca3-b532-2352d161673f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.3669\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.3514\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.3346\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 3.3155\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.2922\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 3.2615\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 3.2175\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.1493\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 3.0461\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.9387\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.9288\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.9229\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.8844\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.8374\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.7983\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.7728\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.7582\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.7478\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.7372\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 2.7254\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.7131\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.7012\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.6901\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.6799\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.6705\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.6610\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 2.6523\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 2.6445\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.6377\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.6329\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.6272\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.6215\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.6141\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 2.6068\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5974\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.5875\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.5797\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.5714\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.5673\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5566\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5406\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.5280\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.5184\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 2.5164\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4959\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.4719\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.4616\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.4533\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 2.4272\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.4100\n",
            "----- temperature: 0.2\n",
            "         te trneeeel l  e             et\n",
            "\n",
            "----- temperature: 0.5\n",
            " a ar  era r  et ule  eaeree  a     e  \n",
            "\n",
            "\n",
            "----- temperature: 1.0\n",
            " ltA\n",
            "efrAneorannau. laboe ee\n",
            "ree\n",
            "l l  io\n",
            "\n",
            "----- temperature: 1.2\n",
            " a.uaul hetr te\n",
            "ttornanhsu .e  itdatt \n",
            "e\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "   import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Sample text data for training\n",
        "text = \"\"\"\n",
        "    Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks\n",
        "    capable of learning unsupervised from data that is unstructured or unlabeled. Also known as\n",
        "    deep neural learning or deep neural network.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocessing the text\n",
        "chars = sorted(list(set(text)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.float32)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.float32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    LSTM(128, input_shape=(maxlen, len(chars))),\n",
        "    Dense(len(chars), activation='softmax')\n",
        "])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x, y, batch_size=128, epochs=50)\n",
        "\n",
        "# Function to sample the next character given the model's predictions\n",
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "# Generate text with correct format\n",
        "def generate_text(model, seed_text, temperature=1.0, num_chars=400):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(num_chars):\n",
        "        sampled = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(generated_text):\n",
        "            sampled[0, t, char_indices[char]] = 1.\n",
        "        preds = model.predict(sampled, verbose=0)[0]\n",
        "        next_index = sample(preds, temperature)\n",
        "        next_char = indices_char[next_index]\n",
        "        generated_text += next_char\n",
        "        generated_text = generated_text[1:]\n",
        "    return generated_text\n",
        "\n",
        "# Generate text with different temperatures\n",
        "start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
        "seed_text = text[start_index: start_index + maxlen]\n",
        "for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print(f'----- temperature: {temperature}')\n",
        "    generated_text = generate_text(model, seed_text, temperature)\n",
        "    print(generated_text)\n",
        "    print()\n"
      ]
    }
  ]
}